from fastapi import FastAPI, HTTPException, Query, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import List, Dict, Optional, Set
import sqlite3
import json
import os
import sys
from pathlib import Path
from datetime import datetime, timedelta
import asyncio
import requests
import feedparser
import re

# Load environment variables if available
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# Simple database path for production
DB_PATH = os.getenv('SQLITE_PATH', '/tmp/news.db')
print(f"Using database at: {DB_PATH}")

def get_db_connection():
    """Get database connection with proper error handling"""
    try:
        conn = sqlite3.connect(DB_PATH, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        return conn
    except Exception as e:
        print(f"Database connection error: {e}")
        # Create directory if needed
        os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
        conn = sqlite3.connect(DB_PATH, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        return conn

def init_db():
    """Initialize database with proper structure"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                link TEXT UNIQUE NOT NULL,
                published TEXT,
                source TEXT,
                raw_text TEXT,
                summary TEXT,
                keywords TEXT,
                category TEXT,
                created_at TEXT DEFAULT (datetime('now'))
            )
        """)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS favorites (
                article_id INTEGER UNIQUE,
                created_at TEXT DEFAULT (datetime('now'))
            )
        """)
        
        # Create indexes
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_articles_published ON articles(published DESC)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_articles_source ON articles(source)")
        
        conn.commit()
        conn.close()
        print("âœ… Database initialized successfully")
        return True
    except Exception as e:
        print(f"âŒ Database initialization failed: {e}")
        return False

app = FastAPI()

# OpenAI API Key from environment variable
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ì´ˆê¸°í™”ëŠ” ì²« ë²ˆì§¸ ìš”ì²­ ì‹œì—ë§Œ ìˆ˜í–‰
_db_initialized = False

def ensure_db_initialized():
    global _db_initialized
    if not _db_initialized:
        try:
            init_db()
            _db_initialized = True
        except Exception as e:
            print(f"Database initialization failed: {e}")
            # Continue without initialization

class Article(BaseModel):
    id: int
    title: str
    link: str
    published: str
    source: str
    summary: Optional[str]
    keywords: Optional[str]
    created_at: Optional[str]
    is_favorite: bool = False

class FavoriteRequest(BaseModel):
    article_id: int

class KeywordStats(BaseModel):
    keyword: str
    count: int

class NetworkNode(BaseModel):
    id: str
    label: str
    value: int

class NetworkEdge(BaseModel):
    from_node: str = None
    to: str
    value: int

    model_config = {"field_alias_generator": None}
    
    def dict(self, **kwargs):
        data = super().model_dump(**kwargs)
        if 'from_node' in data:
            data['from'] = data.pop('from_node')
        return data

class CollectionRequest(BaseModel):
    name: str
    rules: Optional[Dict] = None

class NewsCollectionRequest(BaseModel):
    days: int = 30
    max_pages: int = 5

# get_db_connection is now imported from database module

@app.get("/api/articles")
async def get_articles(
    limit: int = Query(100, le=2000),
    offset: int = Query(0, ge=0),
    source: Optional[str] = None,
    search: Optional[str] = None,
    favorites_only: bool = False,
    date_from: Optional[str] = None,
    date_to: Optional[str] = None
):
    ensure_db_initialized()
    conn = get_db_connection()
    cursor = conn.cursor()
    
    query = "SELECT * FROM articles WHERE 1=1"
    params = []
    
    if source:
        query += " AND source = ?"
        params.append(source)
    
    if search:
        query += " AND (title LIKE ? OR summary LIKE ? OR keywords LIKE ?)"
        search_param = f"%{search}%"
        params.extend([search_param, search_param, search_param])
    
    if favorites_only:
        query += " AND id IN (SELECT article_id FROM favorites)"
    
    if date_from:
        query += " AND DATE(published) >= ?"
        params.append(date_from)
    
    if date_to:
        query += " AND DATE(published) <= ?"
        params.append(date_to)
    
    query += " ORDER BY published DESC LIMIT ? OFFSET ?"
    params.extend([limit, offset])
    
    cursor.execute(query, params)
    articles = []
    
    favorite_ids = set()
    cursor.execute("SELECT article_id FROM favorites")
    favorite_ids = {row[0] for row in cursor.fetchall()}
    
    cursor.execute(query, params)
    for row in cursor.fetchall():
        article = dict(row)
        article['is_favorite'] = article['id'] in favorite_ids
        articles.append(article)
    
    conn.close()
    return articles

@app.get("/api/sources")
async def get_sources():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT DISTINCT source FROM articles ORDER BY source")
    sources = [row[0] for row in cursor.fetchall()]
    conn.close()
    return sources

@app.get("/api/keywords/stats")
async def get_keyword_stats(limit: int = Query(50, le=200)):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT keywords FROM articles WHERE keywords IS NOT NULL")
    
    keyword_counter = {}
    for row in cursor.fetchall():
        keywords = row[0].split(',') if row[0] else []
        for kw in keywords:
            kw = kw.strip()
            if kw:
                keyword_counter[kw] = keyword_counter.get(kw, 0) + 1
    
    conn.close()
    
    sorted_keywords = sorted(keyword_counter.items(), key=lambda x: x[1], reverse=True)[:limit]
    return [{"keyword": k, "count": v} for k, v in sorted_keywords]

@app.get("/api/keywords/network")
async def get_keyword_network(limit: int = Query(30, le=100)):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT keywords FROM articles WHERE keywords IS NOT NULL")
    
    keyword_docs = []
    for row in cursor.fetchall():
        keywords = row[0].split(',') if row[0] else []
        keywords = [kw.strip() for kw in keywords if kw.strip()]
        if keywords:
            keyword_docs.append(keywords)
    
    conn.close()
    
    keyword_counter = {}
    cooccurrence = {}
    
    for doc_keywords in keyword_docs:
        for kw in doc_keywords:
            keyword_counter[kw] = keyword_counter.get(kw, 0) + 1
        
        for i, kw1 in enumerate(doc_keywords):
            for kw2 in doc_keywords[i+1:]:
                pair = tuple(sorted([kw1, kw2]))
                cooccurrence[pair] = cooccurrence.get(pair, 0) + 1
    
    top_keywords = sorted(keyword_counter.items(), key=lambda x: x[1], reverse=True)[:limit]
    top_keyword_set = {k for k, _ in top_keywords}
    
    nodes = [{"id": kw, "label": kw, "value": count} for kw, count in top_keywords]
    edges = []
    
    for (kw1, kw2), weight in cooccurrence.items():
        if kw1 in top_keyword_set and kw2 in top_keyword_set and weight > 1:
            edges.append({"from": kw1, "to": kw2, "value": weight})
    
    return {"nodes": nodes, "edges": edges}

@app.get("/api/favorites")
async def get_favorites():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT a.* FROM articles a
        JOIN favorites f ON a.id = f.article_id
        ORDER BY f.created_at DESC
    """)
    
    favorites = []
    for row in cursor.fetchall():
        article = dict(row)
        article['is_favorite'] = True
        favorites.append(article)
    
    conn.close()
    return favorites

@app.post("/api/favorites/add")
async def add_favorite(request: FavoriteRequest):
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute(
            "INSERT OR IGNORE INTO favorites (article_id) VALUES (?)",
            (request.article_id,)
        )
        conn.commit()
        return {"success": True, "message": "Favorite added"}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        conn.close()

@app.delete("/api/favorites/{article_id}")
async def remove_favorite(article_id: int):
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute("DELETE FROM favorites WHERE article_id = ?", (article_id,))
    conn.commit()
    conn.close()
    
    return {"success": True, "message": "Favorite removed"}

@app.get("/api/stats")
async def get_stats():
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM articles")
    total_articles = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(DISTINCT source) FROM articles")
    total_sources = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM favorites")
    total_favorites = cursor.fetchone()[0]
    
    cursor.execute("""
        SELECT DATE(published) as date, COUNT(*) as count 
        FROM articles 
        WHERE published >= date('now', '-7 days')
        GROUP BY DATE(published)
        ORDER BY date
    """)
    daily_counts = [dict(row) for row in cursor.fetchall()]
    
    conn.close()
    
    return {
        "total_articles": total_articles,
        "total_sources": total_sources,
        "total_favorites": total_favorites,
        "daily_counts": daily_counts
    }

# Inline news collection functions
def collect_from_rss(feed_url: str, source: str, max_items: int = 10):
    """Collect articles from RSS feed"""
    try:
        import feedparser
        import requests
        from datetime import datetime
        
        print(f"ğŸ“¡ Collecting from {source}...")
        
        feed = feedparser.parse(feed_url)
        if not hasattr(feed, 'entries') or not feed.entries:
            return []
        
        articles = []
        for entry in feed.entries[:max_items]:
            try:
                title = getattr(entry, 'title', '').strip()
                link = getattr(entry, 'link', '').strip()
                
                if not title or not link:
                    continue
                
                published = getattr(entry, 'published', datetime.now().strftime('%Y-%m-%d'))
                summary = getattr(entry, 'summary', '')[:500] if hasattr(entry, 'summary') else ''
                
                articles.append({
                    'title': title,
                    'link': link,
                    'published': published,
                    'source': source,
                    'summary': summary
                })
                
            except Exception:
                continue
        
        print(f"âœ… Collected {len(articles)} from {source}")
        return articles
        
    except Exception as e:
        print(f"âŒ Error collecting from {source}: {e}")
        return []

def save_articles_to_db(articles):
    """Save articles to database"""
    if not articles:
        return {'inserted': 0, 'skipped': 0}
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    stats = {'inserted': 0, 'skipped': 0}
    
    for article in articles:
        try:
            cursor.execute("""
                INSERT OR IGNORE INTO articles (title, link, published, source, summary)
                VALUES (?, ?, ?, ?, ?)
            """, (
                article['title'],
                article['link'],
                article['published'],
                article['source'],
                article['summary']
            ))
            
            if cursor.rowcount > 0:
                stats['inserted'] += 1
            else:
                stats['skipped'] += 1
                
        except Exception:
            stats['skipped'] += 1
    
    conn.commit()
    conn.close()
    return stats

def run_collection():
    """Run news collection from major sources"""
    feeds = [
        {"url": "https://it.donga.com/feeds/rss/", "source": "ITë™ì•„"},
        {"url": "https://rss.etnews.com/Section902.xml", "source": "ì „ìì‹ ë¬¸"},
        {"url": "https://techcrunch.com/feed/", "source": "TechCrunch"},
        {"url": "https://www.theverge.com/rss/index.xml", "source": "The Verge"},
        {"url": "https://www.engadget.com/rss.xml", "source": "Engadget"},
    ]
    
    all_articles = []
    for feed in feeds:
        articles = collect_from_rss(feed["url"], feed["source"])
        all_articles.extend(articles)
    
    if all_articles:
        stats = save_articles_to_db(all_articles)
        return True, len(all_articles), stats
    
    return False, 0, {}

# ë‰´ìŠ¤ ìˆ˜ì§‘ API
@app.post("/api/collect-news")
async def collect_news(background_tasks: BackgroundTasks):
    """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    try:
        background_tasks.add_task(run_background_collection)
        return {"message": "ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.", "status": "started"}
    except Exception as e:
        return {"message": f"ì˜¤ë¥˜: {str(e)}", "status": "error"}

async def run_background_collection():
    """ë°±ê·¸ë¼ìš´ë“œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    try:
        success, count, stats = run_collection()
        print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {count}ê°œ ì²˜ë¦¬, {stats.get('inserted', 0)}ê°œ ì‹ ê·œ")
    except Exception as e:
        print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

# ìˆ˜ë™ ë‰´ìŠ¤ ìˆ˜ì§‘ ì—”ë“œí¬ì¸íŠ¸ (ì¦‰ì‹œ ì‹¤í–‰)
@app.post("/api/collect-news-now")
async def collect_news_now():
    """ì¦‰ì‹œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    try:
        success, count, stats = run_collection()
        
        if success:
            # í˜„ì¬ í†µê³„
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM articles")
            total = cursor.fetchone()[0]
            cursor.execute("SELECT source, COUNT(*) FROM articles GROUP BY source ORDER BY COUNT(*) DESC")
            by_source = dict(cursor.fetchall())
            conn.close()
            
            return {
                "message": f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {stats.get('inserted', 0)}ê°œ ì‹ ê·œ ì¶”ê°€",
                "status": "success",
                "processed": count,
                "inserted": stats.get('inserted', 0),
                "skipped": stats.get('skipped', 0),
                "total_articles": total,
                "by_source": by_source
            }
        else:
            return {"message": "ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨", "status": "error"}
            
    except Exception as e:
        return {"message": f"ì˜¤ë¥˜: {str(e)}", "status": "error"}

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • (React ë¹Œë“œ íŒŒì¼)
frontend_dist = Path(__file__).parent.parent / "frontend" / "news-app" / "dist"
if frontend_dist.exists():
    app.mount("/assets", StaticFiles(directory=str(frontend_dist / "assets")), name="assets")
    
    @app.get("/")
    async def serve_frontend():
        index_path = frontend_dist / "index.html"
        if index_path.exists():
            return FileResponse(str(index_path))
        else:
            return {"message": "Frontend not built. Please run 'npm run build' in frontend/news-app directory"}
else:
    @app.get("/")
    async def root():
        return {"message": "News API Server is running. Frontend not found."}

# ì»¬ë ‰ì…˜ ê´€ë¦¬ API
@app.get("/api/collections")
async def get_collections():
    """ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        ensure_db_initialized()
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM articles")
        
        # Simple collection without complex dependencies
        articles_data = []
        for row in cursor.fetchall():
            articles_data.append(dict(row))
        
        if not articles_data:
            return []
        
        # Return simple collections without pandas dependency
        collections = [
            {
                "name": "ë°˜ë„ì²´ ë™í–¥",
                "count": len([a for a in articles_data if any(keyword in (a.get('keywords', '') or '') for keyword in ['ë°˜ë„ì²´', 'ë©”ëª¨ë¦¬', 'ì‹œìŠ¤í…œë°˜ë„ì²´'])]),
                "rules": {"include_keywords": ["ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "ì‹œìŠ¤í…œë°˜ë„ì²´"]},
                "articles": []
            },
            {
                "name": "AI/ë°ì´í„°ì„¼í„°", 
                "count": len([a for a in articles_data if any(keyword in (a.get('keywords', '') or '') for keyword in ['AI', 'ì¸ê³µì§€ëŠ¥', 'ë°ì´í„°ì„¼í„°'])]),
                "rules": {"include_keywords": ["AI", "ì¸ê³µì§€ëŠ¥", "ë°ì´í„°ì„¼í„°"]},
                "articles": []
            }
        ]
        
        conn.close()
        return collections
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/collections")
async def create_collection(request: CollectionRequest):
    """ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        ensure_db_initialized()
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM articles")
        
        articles_data = [dict(row) for row in cursor.fetchall()]
        if not articles_data:
            raise HTTPException(status_code=400, detail="ê¸°ì‚¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # Simple collection creation without complex dependencies
        conn.close()
        return {"message": f"ì»¬ë ‰ì…˜ '{request.name}' ìƒì„± ì™„ë£Œ", "added_articles": len(articles_data)}
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# í‚¤ì›Œë“œ ì¶”ì¶œ API  
@app.post("/api/extract-keywords/{article_id}")
async def extract_article_keywords(article_id: int):
    """íŠ¹ì • ê¸°ì‚¬ì˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT title, summary FROM articles WHERE id = ?", (article_id,))
        article = cursor.fetchone()
        
        if not article:
            raise HTTPException(status_code=404, detail="ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        text = f"{article['title']} {article['summary'] or ''}"
        keywords = extract_keywords(text)
        
        # í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸
        cursor.execute("UPDATE articles SET keywords = ? WHERE id = ?", 
                      (",".join(keywords), article_id))
        conn.commit()
        conn.close()
        
        return {"keywords": keywords, "message": "í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

# ë²ˆì—­ API
@app.post("/api/translate/{article_id}")  
async def translate_article(article_id: int):
    """íŠ¹ì • ê¸°ì‚¬ë¥¼ ë²ˆì—­í•©ë‹ˆë‹¤."""
    try:
        ensure_db_initialized()
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM articles WHERE id = ?", (article_id,))
        article = cursor.fetchone()
        
        if not article:
            raise HTTPException(status_code=404, detail="ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # Simple response without translation service
        article_dict = dict(article)
        conn.close()
        
        return {"message": "ë²ˆì—­ ê¸°ëŠ¥ì€ í˜„ì¬ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "article": article_dict}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë²ˆì—­ ì‹¤íŒ¨: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)